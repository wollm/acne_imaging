{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Acne Detection Model Training with YOLO\n",
        "\n",
        "This Jupyter notebook outlines the steps taken to train an acne detection model using the YOLO (You Only Look Once) architecture. The goal is to accurately classify and localize different types of acne in images. We utilize the Ultralytics YOLO implementation for model training and deployment."
      ],
      "metadata": {
        "id": "QejiIngoahiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "To ensure the notebook runs smoothly, we first need to install the necessary Python packages. We are using the Ultralytics library for YOLO and PyTorch as our machine learning framework.\n"
      ],
      "metadata": {
        "id": "5mjP5X_ZavTW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klysI2xhl4US"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries\n",
        "We import necessary Python libraries that will be used throughout the notebook. This includes components for handling images, managing file paths, and plotting. We also mount our Google Drive to allow for easy access to our data files."
      ],
      "metadata": {
        "id": "ix11ISg8a1Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os"
      ],
      "metadata": {
        "id": "9cgRYCqTa4tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Preprocessing\n",
        "Here, we define a function to load and preprocess images. This preprocessing step is crucial for preparing images for model training and inference."
      ],
      "metadata": {
        "id": "6Sy9QdTobM5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    # Additional preprocessing steps can be added here\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "KWh8kC5cqR34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Displaying Preprocessed Images\n",
        "Example usage of the preprocessing function. This section is particularly useful for visually verifying the preprocessing effects on sample images."
      ],
      "metadata": {
        "id": "ZBO1YzSobUyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/MyDrive/acne/train/images/levle2_65_jpg.rf.e86a2d7a1fd31703745fb935d8679f7e.jpg'\n",
        "preprocessed_image = preprocess_image(image_path)\n",
        "display(preprocessed_image)  # Show the preprocessed image in Google Colab"
      ],
      "metadata": {
        "id": "FmhabDWQbWfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label Handling and Distribution Analysis\n",
        "This part deals with loading label data and visualizing the distribution of different acne types across the training, validation, and test sets."
      ],
      "metadata": {
        "id": "1DALslwybdRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the labels directories\n",
        "train_labels = '/content/drive/MyDrive/acne/train/labels/'\n",
        "test_labels = '/content/drive/MyDrive/acne/test/labels/'\n",
        "valid_labels = '/content/drive/MyDrive/acne/valid/labels/'\n",
        "data_yaml = '/content/drive/MyDrive/acne/data.yaml'\n",
        "\n",
        "# List of label names corresponding to label numbers\n",
        "label_names = ['blackheads', 'dark spot', 'nodules', 'papules', 'pustules', 'whiteheads']\n",
        "\n",
        "def plot_label_distribution(labels_dir, label_names):\n",
        "    \"\"\"\n",
        "    Plots the distribution of labels within a given directory of label files.\n",
        "\n",
        "    Args:\n",
        "    labels_dir (str): The directory path where label files are stored.\n",
        "    label_names (list): A list of label names corresponding to label indices.\n",
        "    plot_size (tuple): A tuple (width, height) specifying the size of the plot in inches.\n",
        "    \"\"\"\n",
        "    # Initialize a dictionary to count the frequency of each label\n",
        "    label_counts = {name: 0 for name in label_names}\n",
        "\n",
        "    image_num = 0\n",
        "\n",
        "    # Read each file in the directory\n",
        "    for filename in os.listdir(labels_dir):\n",
        "        if filename.endswith('.txt'):\n",
        "            image_num += 1\n",
        "            file_path = os.path.join(labels_dir, filename)\n",
        "            with open(file_path, 'r') as file:\n",
        "                for line in file:\n",
        "                    label_index = int(line.split()[0])  # The first element in each line is the label index\n",
        "                    label_counts[label_names[label_index]] += 1  # Increment the count for the corresponding label name\n",
        "\n",
        "    # Plotting the label distribution\n",
        "    labels = list(label_counts.keys())\n",
        "    counts = list(label_counts.values())\n",
        "\n",
        "    plt.figure(figsize=plot_size)\n",
        "    plt.bar(labels, counts, color='blue')\n",
        "    plt.xlabel('Labels')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title(f'Distribution of Labels in \"{get_set(labels_dir).capitalize()}\" Set')\n",
        "    plt.xticks(rotation=45)  # Rotate labels to improve readability\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Number of images: {image_num}\")\n",
        "\n",
        "def get_set(path):\n",
        "    \"\"\"\n",
        "    Extracts the last non-empty word from a string of words separated by slashes.\n",
        "\n",
        "    Args:\n",
        "    path (str): The input string path with words separated by slashes.\n",
        "\n",
        "    Returns:\n",
        "    str: The last non-empty word in the path.\n",
        "    \"\"\"\n",
        "    # Split the string by slashes\n",
        "    parts = path.split('/')\n",
        "    # Filter out any empty strings that result from trailing slashes\n",
        "    parts = [part for part in parts if part]\n",
        "    # Return the last element of the list if it exists, otherwise return an empty string\n",
        "    return parts[-2] if parts else ''\n",
        "\n",
        "# Plotting label distribution for a sample directory\n",
        "plot_label_distribution(train_labels, label_names)\n"
      ],
      "metadata": {
        "id": "qu6wL3PFvd4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Setup and Training\n",
        "Loading a pretrained YOLO model and training it on our dataset."
      ],
      "metadata": {
        "id": "kmt1eDFUcIwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained YOLO model (recommended for training)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=data_yaml, epochs=5, batch=32)"
      ],
      "metadata": {
        "id": "FAV9bsJ-2hog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "This notebook provides a structured approach to training an acne detection model using YOLO. The steps include image preprocessing, label analysis, and model training."
      ],
      "metadata": {
        "id": "IHKxXmS0cX3s"
      }
    }
  ]
}